"""
Host Agent (Port 10023)
- ì „ì²´ ì¡°ìœ¨
- LangGraph ì›Œí¬í”Œë¡œìš°
- RAG ê²€ìƒ‰
- ë³´ê³ ì„œ ìƒì„±
"""

import os
import uuid
from pathlib import Path
from typing import TypedDict, List

from fastapi import FastAPI, HTTPException
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
import httpx

from models.schemas import (
    AnalyzeRequest,
    AnalyzeResponse,
    RAGQueryRequest,
    RAGQueryResponse,
    Article,
    Paper
)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# FastAPI ì•±
app = FastAPI(title="Host Agent", description="íŠ¸ë Œë“œ ë¶„ì„ ì¡°ìœ¨ Agent")

# LLM ì„¤ì •
llm = AzureChatOpenAI(
    azure_endpoint=os.getenv("AOAI_ENDPOINT"),
    api_key=os.getenv("AOAI_API_KEY"),
    deployment_name=os.getenv("AOAI_DEPLOY_GPT4O"),
    api_version=os.getenv("AOAI_API_VERSION", "2024-08-01-preview"),
    temperature=0.7
)

# ì„ë² ë”© ëª¨ë¸
embeddings = AzureOpenAIEmbeddings(
    azure_endpoint=os.getenv("AOAI_ENDPOINT"),
    api_key=os.getenv("AOAI_API_KEY"),
    azure_deployment=os.getenv("AOAI_DEPLOY_EMBED_3_LARGE"),
    chunk_size=1  # ë™ì‹œ ì‚¬ìš© ì œí•œ
)


# ========== State ì •ì˜ ==========

class AgentState(TypedDict):
    """LangGraph State"""
    topic: str
    news: List[dict]
    papers: List[dict]
    report: str
    session_id: str


# ========== vectorstore ê´€ë¦¬ ==========

def save_vectorstore(session_id: str, vectorstore):
    """vectorstore ì €ì¥"""
    try:
        Path("./vector_db").mkdir(exist_ok=True)
        vectorstore.save_local(f"./vector_db/{session_id}")
        print(f"[Host] vectorstore ì €ì¥ ì™„ë£Œ: {session_id}")
    except Exception as e:
        print(f"[Host] vectorstore ì €ì¥ ì‹¤íŒ¨: {e}")


def load_vectorstore(session_id: str):
    """vectorstore ë¡œë“œ"""
    try:
        vectorstore = FAISS.load_local(
            f"./vector_db/{session_id}",
            embeddings,
            allow_dangerous_deserialization=True
        )
        print(f"[Host] vectorstore ë¡œë“œ ì™„ë£Œ: {session_id}")
        return vectorstore
    except Exception as e:
        print(f"[Host] vectorstore ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")


# ========== Node í•¨ìˆ˜ë“¤ ==========

async def fetch_news(state: AgentState) -> dict:
    """ë‰´ìŠ¤ Agent í˜¸ì¶œ"""
    try:
        print(f"[Host] ë‰´ìŠ¤ Agent í˜¸ì¶œ: {state['topic']}")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                "http://localhost:10020/search",
                params={"topic": state["topic"]}
            )
            response.raise_for_status()
        
        news_data = response.json()
        articles = news_data.get("articles", [])
        
        print(f"[Host] ë‰´ìŠ¤ {len(articles)}ê°œ ìˆ˜ì§‘")
        return {"news": articles}
    
    except httpx.TimeoutException:
        print("[Host] ë‰´ìŠ¤ Agent íƒ€ì„ì•„ì›ƒ")
        return {"news": []}
    except Exception as e:
        print(f"[Host] ë‰´ìŠ¤ Agent í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return {"news": []}


async def fetch_papers(state: AgentState) -> dict:
    """ë…¼ë¬¸ Agent í˜¸ì¶œ"""
    try:
        print(f"[Host] ë…¼ë¬¸ Agent í˜¸ì¶œ: {state['topic']}")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                "http://localhost:10021/search",
                params={"topic": state["topic"]}
            )
            response.raise_for_status()
        
        paper_data = response.json()
        papers = paper_data.get("papers", [])
        
        print(f"[Host] ë…¼ë¬¸ {len(papers)}ê°œ ìˆ˜ì§‘")
        return {"papers": papers}
    
    except httpx.TimeoutException:
        print("[Host] ë…¼ë¬¸ Agent íƒ€ì„ì•„ì›ƒ")
        return {"papers": []}
    except Exception as e:
        print(f"[Host] ë…¼ë¬¸ Agent í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return {"papers": []}


async def create_vectorstore(state: AgentState) -> dict:
    """RAGë¥¼ ìœ„í•œ vectorstore ìƒì„±"""
    try:
        print("[Host] vectorstore ìƒì„± ì‹œì‘")
        
        # ë¬¸ì„œ ë³€í™˜
        docs = []
        
        # ë‰´ìŠ¤ â†’ Document
        for article in state["news"]:
            docs.append(Document(
                page_content=f"{article['title']}\n\n{article['summary']}",
                metadata={
                    "source": "news",
                    "title": article["title"],
                    "date": article.get("date", "")
                }
            ))
        
        # ë…¼ë¬¸ â†’ Document
        for paper in state["papers"]:
            docs.append(Document(
                page_content=f"{paper['title']}\n\n{paper['abstract']}",
                metadata={
                    "source": "paper",
                    "title": paper["title"],
                    "authors": ", ".join(paper["authors"]),
                    "url": paper["url"]
                }
            ))
        
        if not docs:
            print("[Host] ë¬¸ì„œê°€ ì—†ì–´ vectorstore ìƒì„± ìŠ¤í‚µ")
            return {}
        
        # ì²­í‚¹
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        split_docs = splitter.split_documents(docs)
        
        # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        vectorstore = FAISS.from_documents(split_docs, embeddings)
        
        # ì €ì¥
        save_vectorstore(state["session_id"], vectorstore)
        
        print(f"[Host] vectorstore ìƒì„± ì™„ë£Œ: {len(split_docs)}ê°œ ì²­í¬")
        return {}
    
    except Exception as e:
        print(f"[Host] vectorstore ìƒì„± ì‹¤íŒ¨: {e}")
        return {}


async def generate_report(state: AgentState) -> dict:
    """ë³´ê³ ì„œ ìƒì„±"""
    try:
        print("[Host] ë³´ê³ ì„œ ìƒì„± ì‹œì‘")
        
        # ê²½ê³  ë©”ì‹œì§€ ìƒì„±
        warnings = []
        if not state["news"]:
            warnings.append("âš ï¸ ë‰´ìŠ¤ ê²€ìƒ‰ì´ ì§€ì—°ë˜ì–´ ë‰´ìŠ¤ ì •ë³´ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if not state["papers"]:
            warnings.append("âš ï¸ ë…¼ë¬¸ ê²€ìƒ‰ì´ ì§€ì—°ë˜ì–´ ë…¼ë¬¸ ì •ë³´ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        if not state["news"] and not state["papers"]:
            return {"report": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì£¼ì œë¡œ ì‹œë„í•´ì£¼ì„¸ìš”."}
        
        # í”„ë¡¬í”„íŠ¸
        prompt = ChatPromptTemplate.from_template(
            """ë‹¹ì‹ ì€ ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ  íŠ¸ë Œë“œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ë³´ê³ ì„œ êµ¬ì„±:
1. ğŸ“Š ì œëª©: "{topic} íŠ¸ë Œë“œ ë³´ê³ ì„œ"
2. ğŸ”¥ í•µì‹¬ íŠ¸ë Œë“œ ìš”ì•½ (3-5ì¤„)
3. ğŸ·ï¸ ì£¼ìš” í‚¤ì›Œë“œ (5ê°œ, í•´ì‹œíƒœê·¸ í˜•ì‹)
4. ğŸ“° ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸ (ìˆëŠ” ê²½ìš°ë§Œ)
5. ğŸ“„ ë…¼ë¬¸ í•˜ì´ë¼ì´íŠ¸ (ìˆëŠ” ê²½ìš°ë§Œ)
6. ğŸ’¡ ì¢…í•© ë¶„ì„

ë‰´ìŠ¤:
{news}

ë…¼ë¬¸:
{papers}

ì£¼ì œ: {topic}
"""
        )
        
        chain = prompt | llm | StrOutputParser()
        report = chain.invoke({
            "topic": state["topic"],
            "news": state["news"] if state["news"] else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ",
            "papers": state["papers"] if state["papers"] else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
        })
        
        # ê²½ê³  ë©”ì‹œì§€ ì¶”ê°€
        if warnings:
            report = "\n".join(warnings) + "\n\n" + report
        
        print("[Host] ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
        return {"report": report}
    
    except Exception as e:
        print(f"[Host] ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
        return {"report": f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"}


# ========== LangGraph êµ¬ì„± ==========

workflow = StateGraph(AgentState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("fetch_news", fetch_news)
workflow.add_node("fetch_papers", fetch_papers)
workflow.add_node("create_vectorstore", create_vectorstore)
workflow.add_node("generate_report", generate_report)

# ì—£ì§€ ì—°ê²°
workflow.set_entry_point("fetch_news")
workflow.add_edge("fetch_news", "fetch_papers")
workflow.add_edge("fetch_papers", "create_vectorstore")
workflow.add_edge("create_vectorstore", "generate_report")
workflow.add_edge("generate_report", END)

# ë©”ëª¨ë¦¬ ì¶”ê°€
memory = MemorySaver()
graph_app = workflow.compile(checkpointer=memory)


# ========== API ì—”ë“œí¬ì¸íŠ¸ ==========

@app.get("/")
async def root():
    """í—¬ìŠ¤ ì²´í¬"""
    return {"status": "ok", "agent": "host"}


@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze_trend(request: AnalyzeRequest):
    """
    íŠ¸ë Œë“œ ë¶„ì„ ì‹¤í–‰
    
    Args:
        request: ë¶„ì„ ìš”ì²­ (topic, max_news, max_papers)
        
    Returns:
        AnalyzeResponse (report, session_id)
    """
    try:
        print(f"[Host] ë¶„ì„ ìš”ì²­: {request.topic}")
        
        # ì„¸ì…˜ ID ìƒì„±
        session_id = str(uuid.uuid4())
        
        # ì„¸ì…˜ë³„ ì‹¤í–‰
        config = {"configurable": {"thread_id": session_id}}
        
        # ì´ˆê¸° ìƒíƒœ
        initial_state = {
            "topic": request.topic,
            "news": [],
            "papers": [],
            "report": "",
            "session_id": session_id
        }
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        result = await graph_app.ainvoke(initial_state, config)
        
        return AnalyzeResponse(
            report=result["report"],
            session_id=session_id
        )
    
    except Exception as e:
        print(f"[Host] ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


@app.post("/rag_query", response_model=RAGQueryResponse)
async def rag_query(request: RAGQueryRequest):
    """
    RAG ê¸°ë°˜ ì¶”ê°€ ì§ˆë¬¸
    
    Args:
        request: RAG ì§ˆì˜ (query, session_id)
        
    Returns:
        RAGQueryResponse (answer)
    """
    try:
        print(f"[Host] RAG ì§ˆì˜: {request.query}")
        
        # vectorstore ë¡œë“œ
        vectorstore = load_vectorstore(request.session_id)
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
        
        # ë¬¸ì„œ í¬ë§·íŒ…
        def format_docs(docs):
            formatted = []
            for i, doc in enumerate(docs, 1):
                source = doc.metadata['source']
                title = doc.metadata['title']
                content = doc.page_content
                formatted.append(
                    f"[ë¬¸ì„œ {i} - {source.upper()}]\n"
                    f"ì œëª©: {title}\n"
                    f"ë‚´ìš©: {content}"
                )
            return "\n\n".join(formatted)
        
        # RAG í”„ë¡¬í”„íŠ¸
        template = """ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
**ë°˜ë“œì‹œ ì–´ë–¤ ë¬¸ì„œë¥¼ ì°¸ê³ í–ˆëŠ”ì§€ [ë¬¸ì„œ N] í˜•ì‹ìœ¼ë¡œ ëª…ì‹œí•˜ì„¸ìš”.**
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.

ì°¸ê³  ë¬¸ì„œ:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€ (ì¶œì²˜ í¬í•¨):
"""
        
        prompt = ChatPromptTemplate.from_template(template)
        
        # RAG ì²´ì¸
        chain = (
            {
                "context": retriever | format_docs,
                "question": RunnablePassthrough()
            }
            | prompt
            | llm
            | StrOutputParser()
        )
        
        answer = chain.invoke(request.query)
        
        print("[Host] RAG ì§ˆì˜ ì™„ë£Œ")
        return RAGQueryResponse(answer=answer)
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"[Host] RAG ì§ˆì˜ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=10023)