"""
Host Agent (Port 10023)
- ì „ì²´ ì¡°ìœ¨
- LangGraph ì›Œí¬í”Œë¡œìš°
- RAG ê²€ìƒ‰
- ë³´ê³ ì„œ ìƒì„±
"""

import os
import uuid
from pathlib import Path
from typing import TypedDict, List
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
import httpx

from models.schemas import (
    AnalyzeRequest,
    AnalyzeResponse,
    RAGQueryRequest,
    RAGQueryResponse,
    Article,
    Paper
)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


# ========== Agent ìë™ ë°œê²¬ ==========

async def discover_agents():
    """
    Agent ìë™ ë°œê²¬
    ê° Agentì˜ AgentCardë¥¼ ì¡°íšŒí•˜ì—¬ ì •ë³´ ìˆ˜ì§‘
    """
    agent_urls = [
        "http://localhost:10020",
        "http://localhost:10021"
    ]
    
    discovered = []
    
    print("\n[Host] ===== Agent ìë™ ë°œê²¬ ì‹œì‘ =====")
    
    async with httpx.AsyncClient(timeout=5.0) as client:
        for url in agent_urls:
            try:
                response = await client.get(f"{url}/.well-known/agent-card.json")
                response.raise_for_status()
                
                card = response.json()
                discovered.append(card)
                
                print(f"[Host] âœ… Agent ë°œê²¬: {card['name']}")
                print(f"       URL: {card['url']}")
                print(f"       ëŠ¥ë ¥: {[cap['name'] for cap in card['capabilities']]}")
                
            except httpx.ConnectError:
                print(f"[Host] âš ï¸  Agent ì—°ê²° ë¶ˆê°€: {url}")
            except Exception as e:
                print(f"[Host] âŒ Agent ë°œê²¬ ì‹¤íŒ¨ ({url}): {e}")
    
    print(f"[Host] ===== ì´ {len(discovered)}ê°œ Agent ë°œê²¬ ì™„ë£Œ =====\n")
    
    return discovered


# ========== Lifespan ì´ë²¤íŠ¸ ==========

@asynccontextmanager
async def lifespan(app: FastAPI):
    """FastAPI ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬"""
    # Startup
    print("\n[Host] Host Agent ì‹œì‘ ì¤‘...")
    agents = await discover_agents()
    
    if len(agents) < 2:
        print("[Host] âš ï¸  ê²½ê³ : ì¼ë¶€ Agentê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("[Host] ë‰´ìŠ¤ Agent(10020), ë…¼ë¬¸ Agent(10021)ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    
    yield
    
    # Shutdown
    print("\n[Host] Host Agent ì¢…ë£Œ ì¤‘...")


# FastAPI ì•±
app = FastAPI(
    title="Host Agent",
    description="íŠ¸ë Œë“œ ë¶„ì„ ì¡°ìœ¨ Agent",
    lifespan=lifespan
)

# LLM ì„¤ì •
llm = AzureChatOpenAI(
    azure_endpoint=os.getenv("AOAI_ENDPOINT"),
    api_key=os.getenv("AOAI_API_KEY"),
    deployment_name=os.getenv("AOAI_DEPLOY_GPT4O"),
    api_version=os.getenv("AOAI_API_VERSION", "2024-08-01-preview"),
    temperature=0.7
)

# ì„ë² ë”© ëª¨ë¸
embeddings = AzureOpenAIEmbeddings(
    azure_endpoint=os.getenv("AOAI_ENDPOINT"),
    api_key=os.getenv("AOAI_API_KEY"),
    azure_deployment=os.getenv("AOAI_DEPLOY_EMBED_3_LARGE"),
    chunk_size=1
)


# ========== State ì •ì˜ ==========

class AgentState(TypedDict):
    """LangGraph State"""
    topic: str
    news: List[dict]
    papers: List[dict]
    report: str
    session_id: str


# ========== vectorstore ê´€ë¦¬ ==========

def save_vectorstore(session_id: str, vectorstore):
    """vectorstore ì €ì¥"""
    try:
        Path("./vector_db").mkdir(exist_ok=True)
        vectorstore.save_local(f"./vector_db/{session_id}")
        print(f"[Host] vectorstore ì €ì¥ ì™„ë£Œ: {session_id}")
    except Exception as e:
        print(f"[Host] vectorstore ì €ì¥ ì‹¤íŒ¨: {e}")


def load_vectorstore(session_id: str):
    """vectorstore ë¡œë“œ"""
    try:
        vectorstore = FAISS.load_local(
            f"./vector_db/{session_id}",
            embeddings,
            allow_dangerous_deserialization=True
        )
        print(f"[Host] vectorstore ë¡œë“œ ì™„ë£Œ: {session_id}")
        return vectorstore
    except Exception as e:
        print(f"[Host] vectorstore ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")


# ========== Node í•¨ìˆ˜ë“¤ ==========

async def fetch_news(state: AgentState) -> dict:
    """ë‰´ìŠ¤ Agent í˜¸ì¶œ"""
    try:
        print(f"[Host] ë‰´ìŠ¤ Agent í˜¸ì¶œ: {state['topic']}")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                "http://localhost:10020/search",
                params={"topic": state["topic"]}
            )
            response.raise_for_status()
        
        news_data = response.json()
        articles = news_data.get("articles", [])
        
        print(f"[Host] ë‰´ìŠ¤ {len(articles)}ê°œ ìˆ˜ì§‘")
        return {"news": articles}
    
    except httpx.TimeoutException:
        print("[Host] ë‰´ìŠ¤ Agent íƒ€ì„ì•„ì›ƒ")
        return {"news": []}
    except Exception as e:
        print(f"[Host] ë‰´ìŠ¤ Agent í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return {"news": []}


async def fetch_papers(state: AgentState) -> dict:
    """ë…¼ë¬¸ Agent í˜¸ì¶œ"""
    try:
        print(f"[Host] ë…¼ë¬¸ Agent í˜¸ì¶œ: {state['topic']}")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                "http://localhost:10021/search",
                params={"topic": state["topic"]}
            )
            response.raise_for_status()
        
        paper_data = response.json()
        papers = paper_data.get("papers", [])
        
        print(f"[Host] ë…¼ë¬¸ {len(papers)}ê°œ ìˆ˜ì§‘")
        return {"papers": papers}
    
    except httpx.TimeoutException:
        print("[Host] ë…¼ë¬¸ Agent íƒ€ì„ì•„ì›ƒ")
        return {"papers": []}
    except Exception as e:
        print(f"[Host] ë…¼ë¬¸ Agent í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return {"papers": []}


async def create_vectorstore(state: AgentState) -> dict:
    """RAGë¥¼ ìœ„í•œ vectorstore ìƒì„±"""
    try:
        print("[Host] vectorstore ìƒì„± ì‹œì‘")
        
        # ë¬¸ì„œ ë³€í™˜
        docs = []
        
        # ë‰´ìŠ¤ â†’ Document
        for article in state["news"]:
            docs.append(Document(
                page_content=f"{article['title']}\n\n{article['summary']}",
                metadata={
                    "source": "news",
                    "title": article["title"],
                    "date": article.get("date", "")
                }
            ))
        
        # ë…¼ë¬¸ â†’ Document
        for paper in state["papers"]:
            docs.append(Document(
                page_content=f"{paper['title']}\n\n{paper['abstract']}",
                metadata={
                    "source": "paper",
                    "title": paper["title"],
                    "authors": ", ".join(paper["authors"]),
                    "url": paper["url"]
                }
            ))
        
        if not docs:
            print("[Host] ë¬¸ì„œê°€ ì—†ì–´ vectorstore ìƒì„± ìŠ¤í‚µ")
            return {}
        
        # ì²­í‚¹
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        split_docs = splitter.split_documents(docs)
        
        # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        vectorstore = FAISS.from_documents(split_docs, embeddings)
        
        # ì €ì¥
        save_vectorstore(state["session_id"], vectorstore)
        
        print(f"[Host] vectorstore ìƒì„± ì™„ë£Œ: {len(split_docs)}ê°œ ì²­í¬")
        return {}
    
    except Exception as e:
        print(f"[Host] vectorstore ìƒì„± ì‹¤íŒ¨: {e}")
        return {}


async def generate_report(state: AgentState) -> dict:
    """ë³´ê³ ì„œ ìƒì„±"""
    try:
        print("[Host] ë³´ê³ ì„œ ìƒì„± ì‹œì‘")
        
        # ê²½ê³  ë©”ì‹œì§€ ìƒì„±
        warnings = []
        if not state["news"]:
            warnings.append("âš ï¸ ë‰´ìŠ¤ ê²€ìƒ‰ì´ ì§€ì—°ë˜ì–´ ë‰´ìŠ¤ ì •ë³´ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if not state["papers"]:
            warnings.append("âš ï¸ ë…¼ë¬¸ ê²€ìƒ‰ì´ ì§€ì—°ë˜ì–´ ë…¼ë¬¸ ì •ë³´ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        if not state["news"] and not state["papers"]:
            return {"report": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì£¼ì œë¡œ ì‹œë„í•´ì£¼ì„¸ìš”."}
        
        # í”„ë¡¬í”„íŠ¸
        prompt = ChatPromptTemplate.from_template(
            """ë‹¹ì‹ ì€ ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ  íŠ¸ë Œë“œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ë³´ê³ ì„œ êµ¬ì„±:
1. ğŸ“Š ì œëª©: "{topic} íŠ¸ë Œë“œ ë³´ê³ ì„œ"
2. ğŸ”¥ í•µì‹¬ íŠ¸ë Œë“œ ìš”ì•½ (3-5ì¤„)
3. ğŸ·ï¸ ì£¼ìš” í‚¤ì›Œë“œ (5ê°œ, í•´ì‹œíƒœê·¸ í˜•ì‹)
4. ğŸ“° ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸ (ìˆëŠ” ê²½ìš°ë§Œ)
5. ğŸ“„ ë…¼ë¬¸ í•˜ì´ë¼ì´íŠ¸ (ìˆëŠ” ê²½ìš°ë§Œ)
6. ğŸ’¡ ì¢…í•© ë¶„ì„

ë‰´ìŠ¤:
{news}

ë…¼ë¬¸:
{papers}

ì£¼ì œ: {topic}
"""
        )
        
        chain = prompt | llm | StrOutputParser()
        report = chain.invoke({
            "topic": state["topic"],
            "news": state["news"] if state["news"] else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ",
            "papers": state["papers"] if state["papers"] else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
        })
        
        # ê²½ê³  ë©”ì‹œì§€ ì¶”ê°€
        if warnings:
            report = "\n".join(warnings) + "\n\n" + report
        
        print("[Host] ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
        return {"report": report}
    
    except Exception as e:
        print(f"[Host] ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
        return {"report": f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"}


# ========== LangGraph êµ¬ì„± ==========

workflow = StateGraph(AgentState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("fetch_news", fetch_news)
workflow.add_node("fetch_papers", fetch_papers)
workflow.add_node("create_vectorstore", create_vectorstore)
workflow.add_node("generate_report", generate_report)

# ì—£ì§€ ì—°ê²°
workflow.set_entry_point("fetch_news")
workflow.add_edge("fetch_news", "fetch_papers")
workflow.add_edge("fetch_papers", "create_vectorstore")
workflow.add_edge("create_vectorstore", "generate_report")
workflow.add_edge("generate_report", END)

# ë©”ëª¨ë¦¬ ì¶”ê°€
memory = MemorySaver()
graph_app = workflow.compile(checkpointer=memory)


# ========== API ì—”ë“œí¬ì¸íŠ¸ ==========

@app.get("/")
async def root():
    """í—¬ìŠ¤ ì²´í¬"""
    return {"status": "ok", "agent": "host"}


@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze_trend(request: AnalyzeRequest):
    """
    íŠ¸ë Œë“œ ë¶„ì„ ì‹¤í–‰
    
    Args:
        request: ë¶„ì„ ìš”ì²­ (topic, max_news, max_papers)
        
    Returns:
        AnalyzeResponse (report, session_id)
    """
    try:
        print(f"[Host] ë¶„ì„ ìš”ì²­: {request.topic}")
        
        # ì„¸ì…˜ ID ìƒì„±
        session_id = str(uuid.uuid4())
        
        # ì„¸ì…˜ë³„ ì‹¤í–‰
        config = {"configurable": {"thread_id": session_id}}
        
        # ì´ˆê¸° ìƒíƒœ
        initial_state = {
            "topic": request.topic,
            "news": [],
            "papers": [],
            "report": "",
            "session_id": session_id
        }
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        result = await graph_app.ainvoke(initial_state, config)
        
        return AnalyzeResponse(
            report=result["report"],
            session_id=session_id
        )
    
    except Exception as e:
        print(f"[Host] ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


@app.post("/rag_query", response_model=RAGQueryResponse)
async def rag_query(request: RAGQueryRequest):
    """
    RAG ê¸°ë°˜ ì¶”ê°€ ì§ˆë¬¸
    
    Args:
        request: RAG ì§ˆì˜ (query, session_id)
        
    Returns:
        RAGQueryResponse (answer)
    """
    try:
        print(f"[Host] RAG ì§ˆì˜: {request.query}")
        
        # vectorstore ë¡œë“œ
        vectorstore = load_vectorstore(request.session_id)
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
        
        # ë¬¸ì„œ í¬ë§·íŒ…
        def format_docs(docs):
            formatted = []
            for i, doc in enumerate(docs, 1):
                source = doc.metadata['source']
                title = doc.metadata['title']
                content = doc.page_content
                formatted.append(
                    f"[ë¬¸ì„œ {i} - {source.upper()}]\n"
                    f"ì œëª©: {title}\n"
                    f"ë‚´ìš©: {content}"
                )
            return "\n\n".join(formatted)
        
        # RAG í”„ë¡¬í”„íŠ¸
        template = """ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
**ë°˜ë“œì‹œ ì–´ë–¤ ë¬¸ì„œë¥¼ ì°¸ê³ í–ˆëŠ”ì§€ [ë¬¸ì„œ N] í˜•ì‹ìœ¼ë¡œ ëª…ì‹œí•˜ì„¸ìš”.**
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.

ì°¸ê³  ë¬¸ì„œ:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€ (ì¶œì²˜ í¬í•¨):
"""
        
        prompt = ChatPromptTemplate.from_template(template)
        
        # RAG ì²´ì¸
        chain = (
            {
                "context": retriever | format_docs,
                "question": RunnablePassthrough()
            }
            | prompt
            | llm
            | StrOutputParser()
        )
        
        answer = chain.invoke(request.query)
        
        print("[Host] RAG ì§ˆì˜ ì™„ë£Œ")
        return RAGQueryResponse(answer=answer)
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"[Host] RAG ì§ˆì˜ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


@app.get("/.well-known/agent-card.json")
async def agent_card():
    """
    Agent Card - A2A í‘œì¤€ í”„ë¡œí† ì½œ
    Agentì˜ ëŠ¥ë ¥ê³¼ ìŠ¤í™ì„ ê³µê°œ
    """
    return {
        "version": "1.0.0",
        "name": "Host Agent",
        "description": "íŠ¸ë Œë“œ ë¶„ì„ ì¡°ìœ¨ Agent. Multi-Agent í˜‘ì—… ë° RAG ê¸°ë°˜ Q&A ì œê³µ.",
        "url": "http://localhost:10023",
        "capabilities": [
            {
                "name": "analyze_trend",
                "description": "ê¸°ìˆ  íŠ¸ë Œë“œ ìë™ ë¶„ì„ (ë‰´ìŠ¤ + ë…¼ë¬¸ í†µí•©)",
                "endpoint": "/analyze",
                "method": "POST",
                "parameters": {
                    "topic": {
                        "type": "string",
                        "description": "ë¶„ì„í•  ê¸°ìˆ  ì£¼ì œ",
                        "required": True,
                        "example": "RAG"
                    },
                    "max_news": {
                        "type": "integer",
                        "description": "ìµœëŒ€ ë‰´ìŠ¤ ê°œìˆ˜",
                        "required": False,
                        "default": 5
                    },
                    "max_papers": {
                        "type": "integer",
                        "description": "ìµœëŒ€ ë…¼ë¬¸ ê°œìˆ˜",
                        "required": False,
                        "default": 5
                    }
                },
                "response_schema": {
                    "type": "AnalyzeResponse",
                    "properties": {
                        "report": "string (markdown)",
                        "session_id": "string (uuid)"
                    }
                }
            },
            {
                "name": "rag_query",
                "description": "RAG ê¸°ë°˜ ì¶”ê°€ ì§ˆë¬¸ (ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)",
                "endpoint": "/rag_query",
                "method": "POST",
                "parameters": {
                    "query": {
                        "type": "string",
                        "description": "ì§ˆë¬¸ ë‚´ìš©",
                        "required": True,
                        "example": "RAG êµ¬í˜„ ì‹œ ì£¼ì˜ì‚¬í•­ì€?"
                    },
                    "session_id": {
                        "type": "string",
                        "description": "ë¶„ì„ ì„¸ì…˜ ID",
                        "required": True
                    }
                },
                "response_schema": {
                    "type": "RAGQueryResponse",
                    "properties": {
                        "answer": "string (ì¶œì²˜ í¬í•¨)"
                    }
                }
            }
        ],
        "dependencies": [
            {
                "name": "ë‰´ìŠ¤ Agent",
                "url": "http://localhost:10020",
                "type": "A2A"
            },
            {
                "name": "ë…¼ë¬¸ Agent",
                "url": "http://localhost:10021",
                "type": "A2A"
            }
        ],
        "features": [
            "Multi-Agent A2A í˜‘ì—…",
            "LangGraph ì›Œí¬í”Œë¡œìš°",
            "RAG (Retrieval-Augmented Generation)",
            "Vector Database (FAISS)",
            "ì„¸ì…˜ ê¸°ë°˜ Q&A"
        ],
        "tags": ["orchestration", "rag", "analysis", "multi-agent"],
        "author": "Tech Trend Scout Team",
        "contact": "http://localhost:10023",
        "created_at": "2025-01-13",
        "updated_at": "2025-01-13"
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=10023)